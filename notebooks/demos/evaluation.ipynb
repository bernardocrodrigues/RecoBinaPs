{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation of Recommender Systems\n",
    "\n",
    "This notebook exemplifies how to evaluate the performance of a recommender\n",
    "system using the implementation from evaluation.benchmark module.\n",
    "\n",
    "Copyright 2024 Bernardo C. Rodrigues\n",
    "\n",
    "See COPYING file for license details"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup notebook\n",
    "import random\n",
    "import numpy as np\n",
    "import evaluation.plot as plot\n",
    "\n",
    "# Load the autoreload extension\n",
    "%load_ext autoreload\n",
    "\n",
    "# Set autoreload to reload all modules every time a cell is executed\n",
    "%autoreload 2\n",
    "\n",
    "# Call the function to customize the default template\n",
    "plot.customize_default_template()\n",
    "\n",
    "seed = 0\n",
    "random.seed(seed)\n",
    "np.random.seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Already downloaded!. Nothing to do.\n"
     ]
    }
   ],
   "source": [
    "from dataset.common import resolve_folds\n",
    "from dataset.movie_lens import load_ml_100k_folds\n",
    "\n",
    "data, k_fold = load_ml_100k_folds()\n",
    "folds = resolve_folds(data, k_fold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from evaluation.strategies import (\n",
    "    MAEStrategy,\n",
    "    RMSEStrategy,\n",
    "    MicroAveragedRecallStrategy,\n",
    "    MacroAveragedRecallStrategy,\n",
    "    RecallAtKStrategy,\n",
    "    MicroAveragedPrecisionStrategy,\n",
    "    MacroAveragedPrecisionStrategy,\n",
    "    PrecisionAtKStrategy,\n",
    "    CountImpossiblePredictionsStrategy,\n",
    ")\n",
    "\n",
    "train_measures = [ ]\n",
    "\n",
    "test_measures = [\n",
    "    MAEStrategy(verbose=False),\n",
    "    RMSEStrategy(verbose=False),\n",
    "    MicroAveragedRecallStrategy(threshold=4.0),\n",
    "    MacroAveragedRecallStrategy(threshold=4.0),\n",
    "    RecallAtKStrategy(k=20, threshold=4.0),\n",
    "    MicroAveragedPrecisionStrategy(threshold=4.0),\n",
    "    MacroAveragedPrecisionStrategy(threshold=4.0),\n",
    "    PrecisionAtKStrategy(k=20, threshold=4.0),\n",
    "    CountImpossiblePredictionsStrategy(),\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from evaluation.benchmark import fit_and_score\n",
    "from surprise.prediction_algorithms import SVD\n",
    "\n",
    "\n",
    "recommender = SVD()\n",
    "\n",
    "_, (trainset, testset) = folds[0]\n",
    "\n",
    "test_measurements, train_measurements, fit_time, test_time = fit_and_score(\n",
    "    recommender_system=recommender,\n",
    "    trainset=trainset,\n",
    "    testset=testset,\n",
    "    test_measures=test_measures,\n",
    "    train_measures=train_measures,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mae                           |  0.750\n",
      "rmse                          |  0.951\n",
      "micro_averaged_recall         |  0.383\n",
      "macro_averaged_recall         |  0.334\n",
      "recall_at_20                  |  0.372\n",
      "micro_averaged_precision      |  0.842\n",
      "macro_averaged_precision      |  0.696\n",
      "precision_at_20               |  0.770\n",
      "count_impossible_predictions  |  0.000\n",
      "Fit time:                     |  0.268\n",
      "Test time:                    |  0.038\n"
     ]
    }
   ],
   "source": [
    "for measure, measurement in test_measurements.items():\n",
    "    print(f\"{measure:<30}|  {measurement:.3f}\")\n",
    "\n",
    "print(f\"Fit time:                     |  {fit_time:.3f}\")\n",
    "print(f\"Test time:                    |  {test_time:.3f}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
