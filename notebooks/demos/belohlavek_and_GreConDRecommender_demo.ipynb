{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GreConDRecommender running over Belohlavek Dataset Demo\n",
    "\n",
    "Copyright 2022 Bernardo C. Rodrigues\n",
    "\n",
    "See COPYING file for license details"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the trainset\n",
    "from tests.ToyDatasets import belohlavek_dataset_raw_rating, convert_raw_rating_list_into_trainset\n",
    "\n",
    "trainset = convert_raw_rating_list_into_trainset(belohlavek_dataset_raw_rating, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from recommenders.grecond_recommender import GreConDRecommender\n",
    "from recommenders.common import cosine_distance\n",
    "\n",
    "algo = GreConDRecommender(knn_distance_strategy=cosine_distance)\n",
    "algo.fit(trainset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Access to formal context\n",
    "from rich.jupyter import print\n",
    "\n",
    "# Note that this concepts are using the internal Trainset representations\n",
    "print(algo.number_of_factors)\n",
    "print(algo.formal_context)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's collect some concept characteristics\n",
    "intent_sizes = []\n",
    "extent_sizes = []\n",
    "concept_sizes = []\n",
    "\n",
    "\n",
    "for formal_concept in algo.formal_context:\n",
    "    formal_concept_intent_size = len(formal_concept.intent)\n",
    "    formal_concept_extent_size = len(formal_concept.extent)\n",
    "\n",
    "    intent_sizes.append(formal_concept_intent_size)\n",
    "    extent_sizes.append(formal_concept_extent_size)\n",
    "\n",
    "    concept_sizes.append(formal_concept_intent_size * formal_concept_extent_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.scatter(intent_sizes, extent_sizes, alpha=1)\n",
    "\n",
    "plt.xlabel(\"Concept Intent Size\")\n",
    "plt.ylabel(\"Concept Extent Size\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(1, 3, figsize=(20, 5))\n",
    "fig.suptitle(\"Concept Histograms\")\n",
    "\n",
    "axs[0].hist(intent_sizes)\n",
    "axs[0].set(xlabel=\"Concept's intent size\", ylabel=\"Occurrences\")\n",
    "\n",
    "axs[1].hist(extent_sizes)\n",
    "axs[1].set(xlabel=\"Concept's extent size\", ylabel=\"Occurrences\")\n",
    "\n",
    "axs[2].hist(concept_sizes)\n",
    "axs[2].set(xlabel=\"Concept's submatrix size\", ylabel=\"Occurrences\")\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.boxplot(\n",
    "    [intent_sizes, extent_sizes, concept_sizes],\n",
    "    labels=[\"Concept's intent size\", \"Concept's extent size\", \"Concept's submatrix size\"],\n",
    ")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Access to factored matrices\n",
    "print(algo.A)\n",
    "print(algo.A.shape)\n",
    "\n",
    "print(algo.B)\n",
    "print(algo.B.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Access to similarity matrix\n",
    "print(algo.sim)\n",
    "print(algo.sim.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate similarity matrix from a vanilla KNN for comparison\n",
    "from surprise.prediction_algorithms import KNNBasic\n",
    "\n",
    "knn_algo = KNNBasic(sim_options={\"name\": \"cosine\"})\n",
    "knn_algo.fit(trainset)\n",
    "\n",
    "print(knn_algo.sim)\n",
    "print(knn_algo.sim.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from recommenders.common import get_similarity_matrix\n",
    "\n",
    "similarity_matrix_on_original_dataset = get_similarity_matrix(algo.binary_dataset)\n",
    "similarity_delta = algo.sim - similarity_matrix_on_original_dataset\n",
    "\n",
    "fig, axs = plt.subplots(1, 4, figsize=(20, 5))\n",
    "fig.suptitle('Similartiy Matrices')\n",
    "\n",
    "subfig = axs[0].imshow(similarity_matrix_on_original_dataset, vmin=0, vmax=1, cmap='Greys')\n",
    "axs[0].set(xlabel='User', ylabel='User', title='Original Dataset Similarity Matrix')\n",
    "fig.colorbar(subfig, ax=axs[1]).set_label('Similarity')\n",
    "\n",
    "subfig = axs[1].imshow(algo.sim, vmin=0, vmax=1, cmap='Greys')\n",
    "axs[1].set(xlabel='User', ylabel='User', title='Latent Space based Similarity Matrix')\n",
    "fig.colorbar(subfig, ax=axs[0]).set_label('Similarity')\n",
    "\n",
    "subfig = axs[2].imshow(similarity_delta, cmap='bwr', vmin=-0.5, vmax=0.5)\n",
    "axs[2].set(xlabel='User', ylabel='User', title='My Toy dataset')\n",
    "fig.colorbar(subfig, ax=axs[2]).set_label('Similarity delta')\n",
    "\n",
    "subfig = axs[3].imshow(knn_algo.sim, cmap='Greys', vmin=0, vmax=1)\n",
    "axs[3].set(xlabel='User', ylabel='User', title='Vanilla KNN Similarity Matrix')\n",
    "fig.colorbar(subfig, ax=axs[3]).set_label('Similarity delta')\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def flatten_similarity_matrix(matrix):\n",
    "    similarities = []\n",
    "    for i, _ in enumerate(matrix):\n",
    "        for j, _ in enumerate(matrix):\n",
    "            if i <= j:\n",
    "                continue\n",
    "            similarities.append(matrix[i,j])\n",
    "    return similarities\n",
    "\n",
    "original_dataset_similarities = flatten_similarity_matrix(similarity_matrix_on_original_dataset)\n",
    "latent_dataset_similarities = flatten_similarity_matrix(algo.sim)\n",
    "\n",
    "\n",
    "plt.boxplot([original_dataset_similarities, latent_dataset_similarities], labels=['Original Dataset', 'Latent Dataset'])\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assert that factorization covers 100% of the original matrix\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "I = np.matmul(algo.A, algo.B)\n",
    "assert (I == algo.binary_dataset.binary_dataset).all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate some predictions\n",
    "testset = trainset.build_testset()\n",
    "predictions = algo.test(testset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Overall quality of the predictions\n",
    "from surprise.accuracy import mae, rmse\n",
    "\n",
    "mae(predictions=predictions)\n",
    "rmse(predictions=predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for prediction in predictions[:10]:\n",
    "    print(prediction)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
